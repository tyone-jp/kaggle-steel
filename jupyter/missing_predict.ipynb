{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.applications import DenseNet121\n",
    "from keras.callbacks import Callback,ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam,Nadam\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50272, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002cc93b.jpg_1</td>\n",
       "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002cc93b.jpg_2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002cc93b.jpg_3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002cc93b.jpg_4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00031f466.jpg_1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId                                      EncodedPixels\n",
       "0  0002cc93b.jpg_1  29102 12 29346 24 29602 24 29858 24 30114 24 3...\n",
       "1  0002cc93b.jpg_2                                                NaN\n",
       "2  0002cc93b.jpg_3                                                NaN\n",
       "3  0002cc93b.jpg_4                                                NaN\n",
       "4  00031f466.jpg_1                                                NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=pd.read_csv('./input/train.csv')\n",
    "print(train_df.shape)\n",
    "train_df.head()s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7204, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>004f40c73.jpg_1</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004f40c73.jpg_2</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004f40c73.jpg_3</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004f40c73.jpg_4</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006f39c41.jpg_1</td>\n",
       "      <td>1 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId EncodedPixels\n",
       "0  004f40c73.jpg_1           1 1\n",
       "1  004f40c73.jpg_2           1 1\n",
       "2  004f40c73.jpg_3           1 1\n",
       "3  004f40c73.jpg_4           1 1\n",
       "4  006f39c41.jpg_1           1 1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df=pd.read_csv('./input/sample_submission.csv')\n",
    "print(submission_df.shape)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['004f40c73.jpg', '006f39c41.jpg', '00b7fb703.jpg', ...,\n",
       "       'ffbf79783.jpg', 'ffc9a6187.jpg', 'ffdb60677.jpg'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_test_images=submission_df['ImageId_ClassId'].apply(lambda x:x.split('_')[0]).unique()\n",
    "unique_test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>isNan</th>\n",
       "      <th>ImageId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002cc93b.jpg_1</td>\n",
       "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
       "      <td>False</td>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002cc93b.jpg_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002cc93b.jpg_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002cc93b.jpg_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00031f466.jpg_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>00031f466.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId                                      EncodedPixels  isNan  \\\n",
       "0  0002cc93b.jpg_1  29102 12 29346 24 29602 24 29858 24 30114 24 3...  False   \n",
       "1  0002cc93b.jpg_2                                                NaN   True   \n",
       "2  0002cc93b.jpg_3                                                NaN   True   \n",
       "3  0002cc93b.jpg_4                                                NaN   True   \n",
       "4  00031f466.jpg_1                                                NaN   True   \n",
       "\n",
       "         ImageId  \n",
       "0  0002cc93b.jpg  \n",
       "1  0002cc93b.jpg  \n",
       "2  0002cc93b.jpg  \n",
       "3  0002cc93b.jpg  \n",
       "4  00031f466.jpg  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['isNan']=pd.isna(train_df['EncodedPixels'])\n",
    "train_df['ImageId']=train_df['ImageId_ClassId'].apply(lambda x:x.split('_')[0])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>missingCount</th>\n",
       "      <th>allMissing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00031f466.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000418bfc.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000789191.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0007a71bf.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId  missingCount  allMissing\n",
       "0  0002cc93b.jpg             3           0\n",
       "1  00031f466.jpg             4           1\n",
       "2  000418bfc.jpg             4           1\n",
       "3  000789191.jpg             4           1\n",
       "4  0007a71bf.jpg             3           0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nan_df=train_df.groupby(by='ImageId',axis=0).agg('sum')\n",
    "train_nan_df.reset_index(inplace=True)\n",
    "train_nan_df.rename(columns={'isNan':'missingCount'},inplace=True)\n",
    "train_nan_df['missingCount']=train_nan_df['missingCount'].astype(np.int32)\n",
    "train_nan_df['allMissing']=(train_nan_df['missingCount']==4).astype(int)\n",
    "\n",
    "train_nan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1801, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>004f40c73.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006f39c41.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00b7fb703.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00bbcd9af.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0108ce457.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId\n",
       "0  004f40c73.jpg\n",
       "1  006f39c41.jpg\n",
       "2  00b7fb703.jpg\n",
       "3  00bbcd9af.jpg\n",
       "4  0108ce457.jpg"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nan_df=pd.DataFrame(unique_test_images,columns=['ImageId'])\n",
    "print(test_nan_df.shape)\n",
    "test_nan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    6239\n",
       "4    5902\n",
       "2     425\n",
       "1       2\n",
       "Name: missingCount, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nan_df['missingCount'].hist()\n",
    "train_nan_df['missingCount'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(code,base,resize=True):\n",
    "    path=f'{base}/{code}'\n",
    "    img=cv2.imread(path)\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    if resize:\n",
    "        img=cv2.resize(img,(256,256))\n",
    "        \n",
    "    return img\n",
    "\n",
    "def validate_path(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 140/12568 [00:06<09:50, 21.05it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7fd0375a99f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_nan_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ImageId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./input/train_images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{train_path}/{path}.png'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-3d6d1e7a8075>\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(code, base, resize)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'{base}/{code}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_path='./tmp/train'\n",
    "validate_path(train_path)\n",
    "\n",
    "for code in tqdm(train_nan_df['ImageId']):\n",
    "    img=load_img(code,base='./input/train_images')\n",
    "    path=code.replace('.jpg','')\n",
    "    cv2.imwrite(f'{train_path}/{path}.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nan_df['ImageId']=train_nan_df['ImageId'].apply(lambda x:x.replace('.jpg','.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10683 validated image filenames.\n",
      "Found 1885 validated image filenames.\n",
      "Found 1801 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=32\n",
    "\n",
    "def create_datagen():\n",
    "    return ImageDataGenerator(zoom_range=0.1,\n",
    "                             fill_mode='constant',\n",
    "                             cval=0.,\n",
    "                             rotation_range=10,\n",
    "                             height_shift_range=0.1,\n",
    "                             width_shift_range=0.1,\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=True,\n",
    "                             rescale=1/255.,\n",
    "                             validation_split=0.15)\n",
    "\n",
    "def create_test_gen():\n",
    "    return ImageDataGenerator(rescale=1/255.).flow_from_dataframe(test_nan_df,\n",
    "                                                                 directory='./input/test_images/',\n",
    "                                                                 x_col='ImageId',\n",
    "                                                                 class_mode=None,\n",
    "                                                                 target_size=(256,256),\n",
    "                                                                 batch_size=BATCH_SIZE,\n",
    "                                                                 shuffle=False)\n",
    "\n",
    "def create_flow(datagen,subset):\n",
    "    return datagen.flow_from_dataframe(train_nan_df,\n",
    "                                      directory='./tmp/train',\n",
    "                                      x_col='ImageId',\n",
    "                                      y_col='allMissing',\n",
    "                                      class_mode='other',\n",
    "                                      target_size=(256,256),\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      subset=subset)\n",
    "\n",
    "data_generator=create_datagen()\n",
    "train_gen=create_flow(data_generator,'training')\n",
    "val_gen=create_flow(data_generator,'validation')\n",
    "test_gen=create_test_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    densenet=DenseNet121(include_top=False,\n",
    "                        input_shape=(256,256,3),\n",
    "                        weights='./input/weight/DenseNet-BC-121-32-no-top.h5'\n",
    "                        )\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(densenet)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(512,activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer=Nadam(),\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0915 22:47:01.676863 140461510276864 deprecation_wrapper.py:119] From /home/tyonetrap/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0915 22:47:01.822533 140461510276864 deprecation_wrapper.py:119] From /home/tyonetrap/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0915 22:47:01.892099 140461510276864 deprecation_wrapper.py:119] From /home/tyonetrap/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0915 22:47:02.008172 140461510276864 deprecation_wrapper.py:119] From /home/tyonetrap/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0915 22:47:02.009001 140461510276864 deprecation_wrapper.py:119] From /home/tyonetrap/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0915 22:47:27.885656 140461510276864 deprecation_wrapper.py:119] From /home/tyonetrap/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0915 22:47:28.035004 140461510276864 deprecation_wrapper.py:119] From /home/tyonetrap/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0915 22:47:29.305835 140461510276864 deprecation_wrapper.py:119] From /home/tyonetrap/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "W0915 22:48:00.288512 140461510276864 deprecation.py:506] From /home/tyonetrap/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0915 22:48:00.457139 140461510276864 deprecation_wrapper.py:119] From /home/tyonetrap/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0915 22:48:00.466782 140461510276864 deprecation.py:323] From /home/tyonetrap/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet121 (Model)          (None, 8, 8, 1024)        7037504   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 7,568,961\n",
      "Trainable params: 7,482,241\n",
      "Non-trainable params: 86,720\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "334/333 [==============================] - 455s 1s/step - loss: 0.6935 - acc: 0.6702 - val_loss: 0.7154 - val_acc: 0.6408\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.64085, saving model to ./output/model.h5\n",
      "Epoch 2/40\n",
      "334/333 [==============================] - 391s 1s/step - loss: 0.4841 - acc: 0.7645 - val_loss: 1.4451 - val_acc: 0.5146\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.64085\n",
      "Epoch 3/40\n",
      "334/333 [==============================] - 390s 1s/step - loss: 0.4067 - acc: 0.8036 - val_loss: 0.4403 - val_acc: 0.7873\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.64085 to 0.78727, saving model to ./output/model.h5\n",
      "Epoch 4/40\n",
      "334/333 [==============================] - 386s 1s/step - loss: 0.3684 - acc: 0.8291 - val_loss: 0.3990 - val_acc: 0.8106\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.78727 to 0.81061, saving model to ./output/model.h5\n",
      "Epoch 5/40\n",
      "334/333 [==============================] - 388s 1s/step - loss: 0.3499 - acc: 0.8425 - val_loss: 1.9991 - val_acc: 0.6228\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.81061\n",
      "Epoch 6/40\n",
      "334/333 [==============================] - 388s 1s/step - loss: 0.3473 - acc: 0.8447 - val_loss: 0.7171 - val_acc: 0.6525\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.81061\n",
      "Epoch 7/40\n",
      "334/333 [==============================] - 389s 1s/step - loss: 0.3273 - acc: 0.8597 - val_loss: 0.4947 - val_acc: 0.7554\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.81061\n",
      "Epoch 8/40\n",
      "334/333 [==============================] - 387s 1s/step - loss: 0.3101 - acc: 0.8640 - val_loss: 2.7826 - val_acc: 0.4844\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.81061\n",
      "Epoch 9/40\n",
      "334/333 [==============================] - 389s 1s/step - loss: 0.2940 - acc: 0.8709 - val_loss: 1.4144 - val_acc: 0.5671\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.81061\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 10/40\n",
      "334/333 [==============================] - 390s 1s/step - loss: 0.2357 - acc: 0.9045 - val_loss: 0.3623 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.81061 to 0.83926, saving model to ./output/model.h5\n",
      "Epoch 11/40\n",
      "334/333 [==============================] - 390s 1s/step - loss: 0.2261 - acc: 0.9069 - val_loss: 0.1778 - val_acc: 0.9310\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.83926 to 0.93103, saving model to ./output/model.h5\n",
      "Epoch 12/40\n",
      "334/333 [==============================] - 391s 1s/step - loss: 0.2101 - acc: 0.9144 - val_loss: 0.2993 - val_acc: 0.8679\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.93103\n",
      "Epoch 13/40\n",
      "334/333 [==============================] - 392s 1s/step - loss: 0.2090 - acc: 0.9179 - val_loss: 1.0856 - val_acc: 0.6987\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.93103\n",
      "Epoch 14/40\n",
      "334/333 [==============================] - 392s 1s/step - loss: 0.2025 - acc: 0.9187 - val_loss: 0.7478 - val_acc: 0.7464\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.93103\n",
      "Epoch 15/40\n",
      "334/333 [==============================] - 390s 1s/step - loss: 0.1880 - acc: 0.9251 - val_loss: 0.2411 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.93103\n",
      "Epoch 16/40\n",
      "334/333 [==============================] - 392s 1s/step - loss: 0.1907 - acc: 0.9238 - val_loss: 0.2625 - val_acc: 0.8886\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.93103\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 17/40\n",
      "334/333 [==============================] - 392s 1s/step - loss: 0.1786 - acc: 0.9280 - val_loss: 0.1709 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.93103 to 0.93422, saving model to ./output/model.h5\n",
      "Epoch 18/40\n",
      "334/333 [==============================] - 391s 1s/step - loss: 0.1767 - acc: 0.9313 - val_loss: 0.1649 - val_acc: 0.9337\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.93422\n",
      "Epoch 19/40\n",
      "334/333 [==============================] - 391s 1s/step - loss: 0.1706 - acc: 0.9323 - val_loss: 0.2304 - val_acc: 0.9045\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.93422\n",
      "Epoch 20/40\n",
      "334/333 [==============================] - 390s 1s/step - loss: 0.1708 - acc: 0.9345 - val_loss: 0.1509 - val_acc: 0.9358\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.93422 to 0.93581, saving model to ./output/model.h5\n",
      "Epoch 21/40\n",
      "334/333 [==============================] - 389s 1s/step - loss: 0.1644 - acc: 0.9369 - val_loss: 0.1466 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.93581 to 0.94536, saving model to ./output/model.h5\n",
      "Epoch 22/40\n",
      "334/333 [==============================] - 390s 1s/step - loss: 0.1668 - acc: 0.9335 - val_loss: 0.1516 - val_acc: 0.9374\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.94536\n",
      "Epoch 23/40\n",
      "334/333 [==============================] - 391s 1s/step - loss: 0.1678 - acc: 0.9326 - val_loss: 0.2618 - val_acc: 0.8881\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.94536\n",
      "Epoch 24/40\n",
      "334/333 [==============================] - 391s 1s/step - loss: 0.1697 - acc: 0.9357 - val_loss: 0.1566 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.94536\n",
      "Epoch 25/40\n",
      "334/333 [==============================] - 389s 1s/step - loss: 0.1692 - acc: 0.9344 - val_loss: 0.1608 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.94536\n",
      "Epoch 26/40\n",
      "334/333 [==============================] - 391s 1s/step - loss: 0.1685 - acc: 0.9356 - val_loss: 0.1478 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.94536\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.0000001313746906e-06.\n",
      "Epoch 27/40\n",
      "334/333 [==============================] - 392s 1s/step - loss: 0.1633 - acc: 0.9353 - val_loss: 0.1460 - val_acc: 0.9432\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.94536\n",
      "Epoch 28/40\n",
      "334/333 [==============================] - 390s 1s/step - loss: 0.1612 - acc: 0.9389 - val_loss: 0.1451 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.94536\n",
      "Epoch 29/40\n",
      "334/333 [==============================] - 389s 1s/step - loss: 0.1613 - acc: 0.9389 - val_loss: 0.1471 - val_acc: 0.9395\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.94536\n",
      "Epoch 30/40\n",
      "334/333 [==============================] - 391s 1s/step - loss: 0.1626 - acc: 0.9341 - val_loss: 0.1492 - val_acc: 0.9379\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.94536\n",
      "Epoch 31/40\n",
      "334/333 [==============================] - 391s 1s/step - loss: 0.1599 - acc: 0.9388 - val_loss: 0.1494 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.94536\n",
      "Epoch 32/40\n",
      "334/333 [==============================] - 390s 1s/step - loss: 0.1574 - acc: 0.9392 - val_loss: 0.1600 - val_acc: 0.9316\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.94536\n",
      "Epoch 33/40\n",
      "334/333 [==============================] - 391s 1s/step - loss: 0.1633 - acc: 0.9383 - val_loss: 0.1503 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.94536\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 34/40\n",
      "334/333 [==============================] - 391s 1s/step - loss: 0.1607 - acc: 0.9359 - val_loss: 0.1485 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.94536\n",
      "Epoch 35/40\n",
      "334/333 [==============================] - 391s 1s/step - loss: 0.1625 - acc: 0.9334 - val_loss: 0.1437 - val_acc: 0.9443\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.94536\n",
      "Epoch 36/40\n",
      "334/333 [==============================] - 391s 1s/step - loss: 0.1684 - acc: 0.9314 - val_loss: 0.1581 - val_acc: 0.9379\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.94536\n",
      "Epoch 37/40\n",
      "334/333 [==============================] - 391s 1s/step - loss: 0.1615 - acc: 0.9389 - val_loss: 0.1433 - val_acc: 0.9401\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.94536\n",
      "Epoch 38/40\n",
      "334/333 [==============================] - 391s 1s/step - loss: 0.1569 - acc: 0.9390 - val_loss: 0.1550 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.94536\n",
      "Epoch 39/40\n",
      "334/333 [==============================] - 389s 1s/step - loss: 0.1628 - acc: 0.9356 - val_loss: 0.1484 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.94536\n",
      "Epoch 40/40\n",
      "334/333 [==============================] - 392s 1s/step - loss: 0.1673 - acc: 0.9329 - val_loss: 0.1424 - val_acc: 0.9443\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.94536\n"
     ]
    }
   ],
   "source": [
    "total_steps=train_nan_df.shape[0]/BATCH_SIZE\n",
    "\n",
    "checkpoint=ModelCheckpoint('./output/model.h5',\n",
    "                          monitor='val_acc',\n",
    "                          verbose=1,\n",
    "                          save_best_only=True,\n",
    "                          save_weights_only=False,\n",
    "                          mode='auto')\n",
    "\n",
    "reduce_lr=ReduceLROnPlateau(monitor='val_loss',\n",
    "                           patience=5,\n",
    "                           verbose=1,\n",
    "                           min_lr=1e-6)\n",
    "\n",
    "history=model.fit_generator(train_gen,\n",
    "                           steps_per_epoch=total_steps*0.85,\n",
    "                           validation_data=val_gen,\n",
    "                           validation_steps=total_steps*0.15,\n",
    "                           epochs=40,\n",
    "                           callbacks=[checkpoint,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4d4dcbd468a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhistory_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhistory_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'acc_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "history_df=pd.DataFrame(history.history)\n",
    "history_df[['loss','val_loss']].plot()\n",
    "history_df[['acc','acc_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tta_prediction(datagen,model,image,n_examples):\n",
    "    samples=np.expand_dims(image,axis=0)\n",
    "    it=datagen.flow(samples,batch_size=n_examples)\n",
    "    yhats=model.predict_generator(it,steps=n_examples,verbose=0)\n",
    "    summed=np.sum(yhats,axis=0)/n_examples\n",
    "    return summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1801/1801 [22:31<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('./output/model.h5')\n",
    "y_test=np.empty(test_nan_df.shape)\n",
    "for i,code in enumerate(tqdm(test_nan_df['ImageId'])):\n",
    "    y_test[i]=tta_prediction(datagen=create_datagen(),\n",
    "                            model=model,\n",
    "                            image=load_img(base='./input/test_images',code=code),\n",
    "                            n_examples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nan_df['allMissing']=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nan_df.to_csv('train_missing_count.csv',index=False)\n",
    "test_nan_df.to_csv('test_missing_count.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
